
---
title: "Initial Analysis"
output:
  workflowr::wflow_html:
    toc: false
    code_folding: hide
---


```{r results='hide', message=FALSE, warning=FALSE, cache=TRUE}
options(warn=-1)

source('lib/functions.R')
source('lib/get_data.R')

opts_chunk$set(cache=TRUE, autodep=TRUE)

db_suffix = '_rr'

read.csv('data/EveningMasterFullAnonym.csv') %>% 
  as.tibble %>% 
{ . } -> df_all


```

# read data
Get Location, accelerometer, wifi, bluetooth

```{r read_data }
my_db_read( paste0( 'select * from location', db_suffix, ' union select * from passivelocation', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_location

my_db_read( paste0( 'select * from accelerometer', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_accelerometer

my_db_read( paste0( 'select * from wifi', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_wifi

my_db_read( paste0( 'select * from bluetooth', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_bluetooth

my_db_read( paste0( 'select * from proximity', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_proximity

my_db_read( paste0( 'select * from connectionstrength', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_connection_strength

my_db_read( paste0( 'select * from battery', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_battery  # is charging

my_db_read( paste0( 'select * from application', db_suffix)) %>% 
  as.tibble() %>% 
  { . } ->  df_application



```

# what are the characteristics of the accellerometer data

1) sometimes, we accellerometer gets stuck, eg 792 for one second
2) even sensor_timestamps, our finest resolution counter, has multiple 
2) but generally, we have 50 samples for each  second measured
3) and generally, there is 50 seconds between samples


```{r play_with_accel}

df_accelerometer %>%
  count( local_time, sort=TRUE ) %>%
  head() %>% kable()

df_accelerometer %>%
  count( sensortime_stamps, sort=TRUE ) %>%
  filter(  n <100 ) %>%
  ggplot( aes( n )) + geom_histogram( bins=100) +
  ggtitle( "number of samples for each sensor_timestamp value")

df_accelerometer %>%
  count( local_time, sort=TRUE ) %>%
  filter(  n <100 ) %>%
  ggplot( aes( n )) + geom_histogram( bins=100) +
  ggtitle( "number of samples for each second")


df_accelerometer %>%
  group_by( userid, night ) %>%
  mutate( idist = local_time - lag( local_time )) %>%
  filter(  idist >1 ) %>%
  count( idist , sort=TRUE) %>%
  ggplot( aes( idist )) + geom_histogram()


```

Using Smart Phone Sensors to Detect Transportation Modes - MDPI
www.mdpi.com/1424-8220/14/11/20843/pdf

2 modes - stationary and moving.
Moving  - 
DFFT features 0, 4.6875, 6.2500, and 11.9141 (Hz), respectively. The indices of the
minimum, maximum, mean, and standard deviation of velocity values, and the SampEn.
stationary:



Average[3]: Average acceleration (for each axis)
• Standard Deviation[3]: Standard deviation (for each axis)
• Average Absolute Difference[3]: Average absolute
difference between the value of each of the 200 readings
within the ED and the mean value over those 200 values
(for each axis)
• Average Resultant Acceleration[1]: Average of the square
roots of the sum of the values of each axis squared
√(x i2 + y i2 + z i2 ) over the ED
• Time Between Peaks[3]: Time in milliseconds between
peaks in the sinusoidal waves associated with most
activities (for each axis)
• Binned Distribution[30]: We determine the range of values
for each axis (maximum – minimum), divide this range into
10 equal sized bins, and then record what fraction of the
200 values fell within each of the bins


```{r use_accel}

df_accelerometer %>%
  mutate ( local_minute = floor_date(local_time, unit = "minutes")) %>%
  group_by( userid, night, local_minute ) %>%
  do( a = fft( zaxis )) %>%
  filter(  idist >1 ) %>%
  count( idist , sort=TRUE) %>%
  ggplot( aes( idist )) + geom_histogram()


df_accelerometer %>%
  mutate ( local_minute = floor_date(local_time, unit = "minutes")) %>%
  head(100 ) -> a

fft(a$zaxis) -> b

plot(b)

plot(a$zaxis) 



```


# how clean is the gps data - Plan
  * for each person / night, what is the range of distance between successive gps points
  * what are the different attributes of gps data (passive/active, etc)

# Data preperation
## merge in passive location
passive location is just as good as active location (but mostly duplicated, we will come to that later

```{r merge}
  
df_location %<>% 
  bind_rows( df_passive_location ) %>%
  mutate( id=row_number() )

```

## data cleaning
1) eliminate duplicates - many duplicate locations at a time stamp. Keep most accurate location at a time stamp
2) many locations at north pole, markedly wrong.  Eliminate them.
3) calculate interval between timestamps




```{r  data_cleaning}

df_filtered_location %>%
  filter(userid=='f181ac9f-f678-40ce-89ea-7d5c807e3b68' & night == '2014-10-18') %>%
  filter( dist_filtered > 10) %>%
  select( id ) %$% id -> b

df_location %>% 
  filter( any( abs(id - b)<10))

  filter( id - b10))



  select(id) %>%
  mutate( id )







df_location %>%
  mutate( my_accuracy = ifelse( longitude < 0 | longitude >10 | latitude <40, 1, 0),
         night = as.factor(night)) %>%
  arrange( userid, night, local_time, my_accuracy, accuracy ) %>%
  group_by( userid, night, local_time ) %>%
  filter( id == min(id ) ) %>% 
  ungroup() %>% 
  filter( my_accuracy == 0 ) %>% 
  select( -my_accuracy ) %>% 
  ungroup() %>%
  group_by( userid, night ) %>%
  filter( length(local_time) > 1 ) %>%
  mutate( interval = difference( local_time, 1 )) %>% 
  ungroup() %>% 
  { . } -> df_best_location

```

# calculate distance 
  - calculate distance between successive best guess locations
  - calculate speed based on interval and distance, in m/sec 


```{r distance}

calc_interval_distance = function( longitude, latitude ) {
  c( longitude, latitude ) %>%
    matrix( ncol = 2 ) %>%
    spDists( segments=TRUE, longlat=TRUE) %>%
    c(0,.)
}

 
calc_distance_from_start = function( longitude, latitude ) {
  c( longitude, latitude ) %>%
    matrix( ncol = 2 ) %>%
    spDistsN1(., .[1,], longlat=TRUE) 
}

df_best_location %>% 
  group_by( night ) %>%
  mutate( dist = calc_interval_distance(longitude, latitude),
         speed = dist/interval * 1000) %>%  # in m/sec
  select( interval, dist, speed, accuracy, bearing, everything())  %>% 
  { . } -> df_filtered_location

```
# Inaccurate GPS investigation
Sometimes, the person 'moves' very quickly;  for example, many samples where speed > 100.  This has to be related to measurement issues

GPS has problems.  There are several solutions
  1. delete out of bounds measurements
  1. average successive points (eg moving average)
  1. use median of successive points (https://gis.stackexchange.com/a/245009/70843)
  1. eliminate changes in location where accellerometer clearly states that the phone is not moving
  1. Calculate Euclidean minimum spanning tree of points:
  1. use a kalman filter, which would use more of teh  sensor data.  Difficult. Here is an impllementation for android (https://blog.maddevs.io/reduce-gps-data-error-on-android-with-kalman-filter-and-accelerometer-43594faed19c)

For this initial work, I use the median 7 filter


```{r dataFiltering}


df_best_location %>%
  group_by( userid, night ) %>%
  mutate( 
         latitude_median = rollapplyr( latitude, 11, median, partial = TRUE ),
         longitude_median = rollapplyr( longitude, 11, median, partial = TRUE ),
#         dist_original = calc_interval_distance(longitude, latitude),
#         dist_cumul_original = calc_distance_from_start(latitude, longitude),
#         speed_original = dist_original/interval * 1000,   # in m/sec
         dist_filtered = calc_interval_distance(latitude_median, longitude_median ),
         dist_cumul_filtered = calc_distance_from_start(latitude_median, longitude_median ),
         speed_filtered = dist_filtered/interval * 1000) %>%  # in m/sec
  select( interval, dist_filtered, speed_filtered, accuracy, bearing, everything())  %>% 
    ungroup() %>%
    { . } -> df_filtered_location



```

# Distance sanity checking
## any points greater than 10km from previous point?

```{r DistanceTesting}
  
df_filtered_location %>% filter( dist_filtered >10 ) %>% head(10) %>% kable()

df_filtered_location %>%
  ungroup() %>%
  arrange( desc(dist_filtered )) %>%
  select( dist_filtered, userid, night ) %>%
  head(20) -> a


a


```

# top 10 raw lat and long points

```{r }

df_filtered_location %>% ungroup() %>% count( longitude, latitude, sort=TRUE) %>% head(10) %>% kable()


```

# distance exploration

```{r distance display}
ggplot(df_filtered_location, aes( latitude )) + geom_histogram()
ggplot(df_filtered_location, aes( longitude )) + geom_histogram()

ggplot(df_filtered_location, aes( dist_original )) +
 geom_histogram() +
 scale_y_log10() +
 xlab( 'range of original distances in km between successive points')


ggplot(df_filtered_location, aes( speed_filtered )) +
 geom_histogram() +
 scale_y_log10() +
 xlab('speed in m/sec between successive filtered points')

ggplot(df_filtered_location, aes( y=speed_filtered, x=night )) +
 geom_violin() + 
 geom_boxplot(width=0.1)+
 scale_y_log10() +
 xlab('speed in m/sec') + 
 ggtitle( 'Range of filtered speeds per night, log scale, outliers dropped')

 
``` 

# Demonstrations of cleaned and uncleaned data

First, the number of points/ night Number with speed > 100 m/s

```{r excess_speed }
df_filtered_location %>% filter( speed_filtered > 100 ) %>% count(sort=TRUE)
df_filtered_location %>% filter( dist_filtered > 100 ) %>% count(sort=TRUE)

#df_filtered_location %>% 
#  ggplot( ) + geom_line( aes( local_time, speed_original  )) +
#  facet_wrap( ~night , scales='free') +
#  ggtitle( "original intersample speed measurements" )
#
#
#df_filtered_location %>% 
#  ggplot( ) + geom_line( aes( local_time, dist_original  )) +
#  facet_wrap( ~night , scales='free') +
#  ggtitle( "original intersample distance measurements" )
#
#df_filtered_location %>% 
#  ggplot( ) + geom_line( aes( local_time, dist_cumul_original  )) +
#  facet_wrap( ~night , scales='free') +
#  ggtitle( "original cumulative distance measurements" )


df_filtered_location %>% 
  inner_join( a, by=c('userid','night')) %>%
  ggplot( ) + geom_line( aes( local_time, speed_filtered  )) +
  facet_wrap( ~userid, scales='free') +
  ggtitle( "Filtered intersample speed measurements" )


df_filtered_location %>% 
  inner_join( a, by=c('userid','night')) %>%
  ggplot( ) + geom_line( aes( local_time, dist_filtered.x  )) +
  facet_wrap( ~userid, scales='free') + 
  ggtitle( "Filtered intersample distance measurements" )



df_filtered_location %>% 
  inner_join( a, by=c('userid','night')) %>%
  ggplot( ) + geom_line( aes( local_time, dist_cumul_filtered  )) +
  facet_wrap( ~userid, scales='free') + 
  ggtitle( "Filtered cumulative distance measurements" )

```

# Heterogeneous Time series exploration: to be continued

```{r time_series}


df_filtered_location %>%  
  as.tsibble( key=id( userid, night), 
             index=local_time, 
             regular=FALSE
             ) %>% 
  { . } ->  ts_location


```


```{r end }

options(warn=0)
```

