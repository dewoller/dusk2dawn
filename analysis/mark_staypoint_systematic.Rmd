---
title: "Staypoint estimation"
output:
  workflowr::wflow_html
---

# Staypoint estimation

We are trying determine what is the set of GPS points that participate in a staypoint

## preliminary data cleaning
1) eliminate duplicates - many duplicate locations at a time stamp. Keep most accurate location at a time stamp
2) many locations at north pole, markedly wrong.  Eliminate them.
3) calculate interval and distance between timestamps

## Determine staypoints

The staypoint determination algorithm uses 4 variables;
 - min_staypoint_time  - minimum time, in minutes, that must stay within max_staypoint_distance
 * max_jump_time - maximum time, in minutes, between readings
 * max_staypoint_distance - maximum distance for readings to be counted as a single staypoint
 * sigma - smoothing parameter.  Smaller is more smooth


```{r results='hide', message=FALSE, warning=FALSE}

options(warn=-1)
library( knitr )
opts_chunk$set(cache=TRUE, autodep=TRUE)

source('lib/functions.R')
source('lib/get_data.R')
source('lib/location_prep.R')
library(tidyverse)
library(lubridate)

# load in the individual locations information
df_location = get_df_location()

# load in the best guess location information
#df_best_location = get_df_best_location( df_location )

```

```{r process_one_set, eval=TRUE}


#debug( do_one_search)
#undebug( do_one_search)

get_pruned_filename = function( sigma ) {

  glue::glue( "data_fast/df_location_pruned_sigma_{sigma}.rds")

}

do_one_prune = function( .sigma ) {

  fname  = get_pruned_filename( .sigma )

  ParallelLogger::logInfo(paste('Starting One prune ', fname))

  df_location %>%
    group_by( userid, night ) %>%
    arrange( timestamp ) %>% 
    group_modify( ~prune_gps_outliers(.x, sigma = .sigma)) %>% 
    saveRDS(file=fname)
  ParallelLogger::logInfo(paste('Finished prune_gps', fname))
  NULL
}



do_one_search = function( .df ) {
  rlimit_stack(10000000)

  ParallelLogger::logInfo(paste('Starting One Search', .df))
  ParallelLogger::logInfo(paste('Starting One Search', .df$i_sigma))
  ParallelLogger::logInfo(paste('str One Search', print(str(.df))))
  in_fname  = get_pruned_filename( .df$i_sigma )
  ParallelLogger::logInfo(paste('Filename One Search', in_fname))

  out_fname  = glue::glue( "data/save_v2_{.df$i_min_staypoint_time}_{.df$i_max_jump_time}_{.df$i_max_staypoint_distance}_{.df$i_sigma}_df.rds")

  if(file.exists(out_fname)) {
    ParallelLogger::logInfo(paste('One Search : file exists:', out_fname))
  } else {
    ParallelLogger::logInfo(paste('One Search : calculating:', out_fname))
    readRDS( in_fname ) %>%
      group_modify( ~findStayPoint(.x,  .df$i_max_jump_time, .df$i_min_staypoint_time, .df$i_max_staypoint_distance)) %>%
      select( local_time, timestamp, n_staypoint, duration, everything()) %>% 
      { . } -> df
      saveRDS(df,  file=out_fname)
  }
  ParallelLogger::logInfo(paste('Ending One Search', out_fname))

  NULL
}


```


# generate a subset of staypoints for a single parameter set


```{r test_with_subset,eval=FALSE }

if( FALSE) {
  df_location %>% 
    #filter(userid=='f181ac9f-f678-40ce-89ea-7d5c807e3b68' & night == '2014-10-18') %>%
    filter( userid=='05f35693-7fec-4372-af78-7bd904c187e0' & night=='2014-10-10'  ) %>% 
    arrange( userid, night, timestamp ) %>%
    { . } -> df_location


  min_staypoint_time=10*60
  max_jump_time=20*60
  max_staypoint_distance=200
  sigma=.5

  list(
  i_min_staypoint_time=min_staypoint_time,
  i_max_jump_time=max_jump_time,
  i_max_staypoint_distance=max_staypoint_distance,
  i_sigma=sigma
      ) %>% as_tibble() %>% 
      { . } -> df

  do_one_search( df )
  cat( df)
  cat("\n")

    df_location %>%  
      group_by( userid, night ) %>%
      arrange( timestamp ) %>%
      group_modify( ~prune_gps_outliers(.x, sigma = sigma)) %>%
      group_modify( ~findStayPoint(.x,  max_jump_time, min_staypoint_time, max_staypoint_distance)) %>%
      select( local_time, timestamp, n_staypoint, duration, distance, everything()) %>% 
      { . } -> b1_m

  b1_m %>% count( n_staypoint )

}
```

# generate a range of staypoint estimates, for a range of parameters


```{r generate_staypoints, eval=TRUE }

min_staypoint_time_range=c(5,10, 15)*60
max_jump_time_range=c(2,5)*60
max_staypoint_distance_range= c(5,10,20)
sigma_range=c(.25, .5, 1, 2, 100)
expand.grid(min_staypoint_time_range,max_jump_time_range,max_staypoint_distance_range, sigma_range ) %>% 
  setNames( qc(i_min_staypoint_time, i_max_jump_time, i_max_staypoint_distance, i_sigma )) %>%
  as_tibble() %>% 
  { . } -> grid_search 
  

library(multidplyr)
library(parallel)
library(ParallelLogger) 
logFileName = 'staypoint_estimation.log'

if( FALSE) {
  # create pruned location sets
  cluster <- makeCluster(7)
  clusterExport(cluster,  qc(df_location, distanceBetween, findStayPoint, distance2centroid, prune_gps_outliers, eliminate_sigma, get_pruned_filename))
  clusterExport(cluster,  qc( prune_gps_outliers, eliminate_sigma, get_pruned_filename))
  clusterEvalQ(cluster, {
                library(glue)
                library(geosphere)
                library(tidyverse)
                NULL
      })
  dummy <- clusterApply(cluster, sigma_range , do_one_prune)
  stopCluster(cluster)
}

cluster <- makeCluster(4)
clusterExport(cluster,  qc(distanceBetween, findStayPoint, distance2centroid, get_pruned_filename))
clusterEvalQ(cluster, {
               library(glue)
               library(geosphere)
               library(tidyverse)
               library(RAppArmor)
               NULL
     })
grid_search  %>% 
  mutate( row = row_number()) %>%
  nest( -row ) %>% 
  { . } -> gs
dummy <- clusterApply(cluster, gs$data , do_one_search)


# single threaded
needs( purrrlyr)
by_row( grid_search, do_one_search)

debug(do_one_search)
undebug(do_one_search)
stopCluster(cluster)



```
