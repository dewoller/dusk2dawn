---
title: "Initial Analysis"
output:
  workflowr::wflow_html
---


```{r results='hide', message=FALSE, warning=FALSE, cache=TRUE}
options(warn=-1)

source('lib/functions.R')
source('lib/get_data.R')

library(tsibble)
library(lubridate)
library(sp)
#library(tidyquant)
opts_chunk$set(cache=TRUE, autodep=TRUE)

read.csv('data/EveningMasterFullAnonym.csv') %>% 
  as.tibble %>% 
{ . } -> df_all
```



```{r read_data }

my_db_read( 'select * from location') %>% 
  as.tibble() %>% 
  { . } ->  df_location

my_db_read( 'select * from passivelocation') %>% 
  as.tibble() %>% 
  { . } ->  df_passive_location
 
```

# how clean is the gps data - Plan
  * for each person / night, what is the range of distance between successive gps points
  * what are the different attributes of gps data (passive/active, etc)

# Data preperation
## merge in passive location
passive location is just as good as active location (but mostly duplicated, we will come to that later

```{r merge}

df_location %<>% 
  bind_rows( df_passive_location ) %>%
  mutate( id=row_number() )

```

## data cleaning
1) eliminate duplicates - many duplicate locations at a time stamp. Keep most accurate location at a time stamp
2) many locations at north pole, markedly wrong.  Eliminate them.
3) calculate interval between timestamps





```{r one_test, eval=FALSE}


df_filtered_location %>%
  filter(userid=='f181ac9f-f678-40ce-89ea-7d5c807e3b68' & night == '2014-10-18') %>%
  filter( dist_filtered > 10) %>%
  select( id ) %$% id -> b
```

```{r  data_cleaning}
library(geosphere)
library(zoo)
library(glue)

distance2centroid = function( df ) {
  # distance from last point to centroid
  distm(
        colMeans( df  %>% select( latitude, longitude )),
        df %>% slice(n()) %>% select( latitude, longitude ),
        fun = distHaversine
  )

}



distanceBetween = function( df ) {
  # distance from last 2 points
  distm(
    df %>% slice(n()-1)   %>% select( latitude, longitude ),
    df %>% slice(n()) %>% select( latitude, longitude ),
    fun = distHaversine
  )

}


findStayPoint = function (df, max_jump_time, min_staypoint_time, max_staypoint_distance) {

  n_staypoint = 0  # 0 not in, 1:n which staypoint
  df$n_staypoint = 0
  df$duration = -1
  df$last_duration = -1
  df$distance = -1
  df$velocity = -1
  df$start = -1
  df$n_staypoint = 0
  n_staypoint = n_staypoint + 1
  in_staypoint=FALSE
  nrow = nrow( df )
  sp_start=1
  sp_end=1

  while ( sp_end <= nrow ) {
    df[ sp_end,]$start = sp_start

    if ( sp_end <= sp_start ) {
      sp_end = sp_end + 1
      next
    }

    last_duration = df[ sp_end, ]$time_stamp - df[ sp_end-1, ]$time_stamp
    entire_duration = df[ sp_end, ]$time_stamp - df[ sp_start, ]$time_stamp
    df[ sp_end,]$duration = entire_duration
    df[ sp_end,]$last_duration = last_duration

    #cat( paste( sp_start, sp_end, 'last_duration', last_duration , 'entire_duration',    entire_duration,in_staypoint,"\n"))

    if ( last_duration >= max_jump_time )   {

        # we have too much time between this point and the last point
        sp_start = sp_end
        if (in_staypoint ){
          n_staypoint = n_staypoint + 1
          in_staypoint = FALSE
        } else {
          # leave untagged points outside staypoint
          df[ sp_start:sp_end,]$distance = -1
        }
        next
    }

    # is this point within current staypoint centroid
    d = distance2centroid( slice( df, sp_start:sp_end ))
    df[ sp_end,]$distance = d
    df[ sp_end,]$velocity = distanceBetween( slice( df, (sp_end-1):sp_end )) / last_duration

    if ( d > max_staypoint_distance ) {

      # we have physically moved out of the previous staypoint zone, sp_start:sp_end
      if ( in_staypoint ){

        # this is a mark, keep the previous staypoint, sp_start afresh
        n_staypoint = n_staypoint + 1
        in_staypoint = FALSE
        sp_start=sp_end
      } else {

        # keep looking, move the staypoint zone forward
        sp_start = sp_start + 1
      }
      next
    }

    # we are within staypoint distance of centroid( sp_start:sp_end )
    if ((entire_duration >= min_staypoint_time ) ) {

      # we have been in staypoint sufficient time
      df[ sp_start:sp_end,]$n_staypoint = n_staypoint
      in_staypoint = TRUE
    }
    sp_end = sp_end + 1
  }

df
}

min_staypoint_time=20*60
max_jump_time=20*60
max_staypoint_distance=200



df_location %>%
  mutate( is_broken_reading = ifelse( longitude < 0 | longitude >10 | latitude <40, 1, 0),
         night = as.factor(night)) %>%
  arrange( userid, night, local_time, is_broken_reading, accuracy ) %>%
  group_by( userid, night, local_time ) %>%
  filter( id == min(id ) ) %>% 
  ungroup() %>% 
  filter( is_broken_reading == 0 ) %>% 
  select( -is_broken_reading ) %>% 
  group_by( userid, night ) %>%
  filter( length(local_time) > 1 ) %>%  # we want people who had at least 1 reading/night
  mutate( interval = difference( local_time, lag=1 )) %>% 
  ungroup() %>% 
  { . } -> df_best_location

df_best_location %>% 
  filter( userid=='05f35693-7fec-4372-af78-7bd904c187e0' & night=='2014-10-10'  ) %>% 
  { . } -> b


b %>% 
  arrange( userid, night, local_time ) %>%
  mutate( longitude = rollapply( data=longitude, align='center', width=5, FUN=mean, fill=NA,NA.rm=TRUE)  ) %>%
  mutate( latitude = rollapply( data=latitude, align='center', width=5, FUN=mean, fill=NA,NA.rm=TRUE)  ) %>%
  drop_na(latitude, longitude) %>%
  group_by( userid, night ) %>%
  group_modify( ~findStayPoint(.x,  max_jump_time, min_staypoint_time, max_staypoint_distance)) %>%
  select( n_staypoint, duration, distance, everything()) %>% 
  { . } -> b1_m

ggplot(b1, aes( velocity)) + geom_histogram()


b %>% 
  arrange( userid, night, local_time ) %>%
  mutate( longitude = rollapply( data=longitude, align='center', width=20, FUN=median, fill=NA,NA.rm=TRUE)  ) %>%
  mutate( latitude = rollapply( data=latitude, align='center', width=20, FUN=median, fill=NA,NA.rm=TRUE)  ) %>%
  drop_na(latitude, longitude) %>%
arrange( local_time ) %>%
group_by( userid, night ) %>%
group_modify( ~findStayPoint(.x,  max_jump_time, min_staypoint_time, max_staypoint_distance)) %>%
  ggplot( aes( longitude, latitude)) + geom_point() + geom_line( aes( size=velocity))

b %>% 
  arrange( userid, night, local_time ) %>%
  gpsbabel( 'simplify,count=100') %>%
  ggplot( aes( longitude, latitude)) + geom_point() + geom_line( )

df=b
parameters='simplify,count=50'


gpsbabel = function( df, parameters ) {

  f_in=tempfile()
  f_out=tempfile()
  f_in='/tmp/a.xml'
  f_out='/tmp/b.xml'

  df %>% 
    mutate( .id = row_number()) %>% 
    { . } -> df


  df %>% 
    select( longitude, latitude, .id ) %>% 
    rename( name=.id) %>% 
    glue_data( '<rtept lat="{latitude}" lon="{longitude}" name="{name}"></rtept>') %>% 
    paste( collapse = "\\n") %>%
    { . } -> body


  writeLines(paste0( "<gpx>\n <rte>\n", body, "</rte>\n</gpx>\n"), f_in)


  system( paste ( " gpsbabel -i gpx -f  ", 
                 f_in,
                 "-x ", 
                 parameters,
                 "-o csv -F ",
                 f_out 
                 )
  )

  read_csv( f_out, col_names=c("longitude", "latitude", ".id"), col_types='ddc') %>%
    mutate( .id = str_replace(.id, 'RPT','') %>% as.numeric()) %>% 
    { . } -> df_simplified

  df %>%
    select( -longitude, -latitude ) %>%
    inner_join( df_simplified, by=".id")  %>%
    select(-.id)

}

b1_m  %>% 
    mutate( id=row_number() ) %>%
    arrange( desc( id )) %>%
  select( id, velocity, n_staypoint, duration, distance, everything()) %>%  View

  { . } -> b1

df_best_location %>% 
  group_by( userid, night ) %>%
  group_modify( ~findStayPoint(.x,  max_jump_time, min_staypoint_time, max_staypoint_distance)) %>%
{ . } -> df_staypoints

df_staypoints %>%
  summarise( n_staypoint = max(n_staypoint ),
            ts = (max( time_stamp) - min(time_stamp)) / 60,
            n=n()
            ) %>%
  filter( ts > 60 & n>10) %>%

```

# calculate distance 
  - calculate distance between successive best guess locations
  - calculate speed based on interval and distance, in m/sec 


```{r distance}

calc_interval_distance = function( longitude, latitude ) {
  c( longitude, latitude ) %>%
    matrix( ncol = 2 ) %>%
    spDists( segments=TRUE, longlat=TRUE) %>%
    c(0,.)
}

 
calc_distance_from_start = function( longitude, latitude ) {
  c( longitude, latitude ) %>%
    matrix( ncol = 2 ) %>%
    spDistsN1(., .[1,], longlat=TRUE) 
}

df_best_location %>% 
  group_by( night ) %>%
  mutate( dist = calc_interval_distance(longitude, latitude),
         speed = dist/interval * 1000) %>%  # in m/sec
  select( interval, dist, speed, accuracy, bearing, everything())  %>% 
  { . } -> df_filtered_location

```
# Inaccurate GPS investigation
Sometimes, the person 'moves' very quickly;  for example, many samples where speed > 100.  This has to be related to measurement issues

GPS has problems.  There are several solutions
  1. delete out of bounds measurements
  1. average successive points (eg moving average)
  1. use median of successive points (https://gis.stackexchange.com/a/245009/70843)
  1. eliminate changes in location where accellerometer clearly states that the phone is not moving
  1. Calculate Euclidean minimum spanning tree of points:
  1. use a kalman filter, which would use more of teh  sensor data.  Difficult. Here is an impllementation for android (https://blog.maddevs.io/reduce-gps-data-error-on-android-with-kalman-filter-and-accelerometer-43594faed19c)

For this initial work, I use the median 7 filter


```{r dataFiltering}


df_best_location %>%
  group_by( userid, night ) %>%
  mutate( 
         latitude_median = rollapplyr( latitude, 11, median, partial = TRUE ),
         longitude_median = rollapplyr( longitude, 11, median, partial = TRUE ),
#         dist_original = calc_interval_distance(longitude, latitude),
#         dist_cumul_original = calc_distance_from_start(latitude, longitude),
#         speed_original = dist_original/interval * 1000,   # in m/sec
         dist_filtered = calc_interval_distance(latitude_median, longitude_median ),
         dist_cumul_filtered = calc_distance_from_start(latitude_median, longitude_median ),
         speed_filtered = dist_filtered/interval * 1000) %>%  # in m/sec
  select( interval, dist_filtered, speed_filtered, accuracy, bearing, everything())  %>% 
    ungroup() %>%
    { . } -> df_filtered_location



```

# Distance sanity checking
## any points greater than 10km from previous point?

```{r DistanceTesting}
  
df_filtered_location %>% filter( dist_filtered >10 ) %>% head(10) %>% kable()

df_filtered_location %>%
  ungroup() %>%
  arrange( desc(dist_filtered )) %>%
  select( dist_filtered, userid, night ) %>%
  head(20) -> a


a


```

# top 10 raw lat and long points

```{r }

df_filtered_location %>% ungroup() %>% count( longitude, latitude, sort=TRUE) %>% head(10) %>% kable()


```

# distance exploration

```{r distance display}
ggplot(df_filtered_location, aes( latitude )) + geom_histogram()
ggplot(df_filtered_location, aes( longitude )) + geom_histogram()

ggplot(df_filtered_location, aes( dist_original )) +
 geom_histogram() +
 scale_y_log10() +
 xlab( 'range of original distances in km between successive points')


ggplot(df_filtered_location, aes( speed_filtered )) +
 geom_histogram() +
 scale_y_log10() +
 xlab('speed in m/sec between successive filtered points')

ggplot(df_filtered_location, aes( y=speed_filtered, x=night )) +
 geom_violin() + 
 geom_boxplot(width=0.1)+
 scale_y_log10() +
 xlab('speed in m/sec') + 
 ggtitle( 'Range of filtered speeds per night, log scale, outliers dropped')

 
``` 

# Demonstrations of cleaned and uncleaned data

First, the number of points/ night Number with speed > 100 m/s

```{r excess_speed }
df_filtered_location %>% filter( speed_filtered > 100 ) %>% count(sort=TRUE)
df_filtered_location %>% filter( dist_filtered > 100 ) %>% count(sort=TRUE)

#df_filtered_location %>% 
#  ggplot( ) + geom_line( aes( local_time, speed_original  )) +
#  facet_wrap( ~night , scales='free') +
#  ggtitle( "original intersample speed measurements" )
#
#
#df_filtered_location %>% 
#  ggplot( ) + geom_line( aes( local_time, dist_original  )) +
#  facet_wrap( ~night , scales='free') +
#  ggtitle( "original intersample distance measurements" )
#
#df_filtered_location %>% 
#  ggplot( ) + geom_line( aes( local_time, dist_cumul_original  )) +
#  facet_wrap( ~night , scales='free') +
#  ggtitle( "original cumulative distance measurements" )


df_filtered_location %>% 
  inner_join( a, by=c('userid','night')) %>%
  ggplot( ) + geom_line( aes( local_time, speed_filtered  )) +
  facet_wrap( ~userid, scales='free') +
  ggtitle( "Filtered intersample speed measurements" )


df_filtered_location %>% 
  inner_join( a, by=c('userid','night')) %>%
  ggplot( ) + geom_line( aes( local_time, dist_filtered.x  )) +
  facet_wrap( ~userid, scales='free') + 
  ggtitle( "Filtered intersample distance measurements" )



df_filtered_location %>% 
  inner_join( a, by=c('userid','night')) %>%
  ggplot( ) + geom_line( aes( local_time, dist_cumul_filtered  )) +
  facet_wrap( ~userid, scales='free') + 
  ggtitle( "Filtered cumulative distance measurements" )

```

# Heterogeneous Time series exploration: to be continued

```{r time_series}


df_filtered_location %>%  
  as.tsibble( key=id( userid, night), 
             index=local_time, 
             regular=FALSE
             ) %>% 
  { . } ->  ts_location


```


```{r end_last }

options(warn=0)
```

